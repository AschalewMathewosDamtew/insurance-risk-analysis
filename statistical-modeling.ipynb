{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\biement fanteye\\AppData\\Local\\Temp\\ipykernel_4264\\2887755012.py:5: DtypeWarning: Columns (32,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('dataset.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation and feature engineering complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Handling Missing Data\n",
    "# Numerical columns - Impute with median\n",
    "numerical_cols = ['SumInsured', 'TotalPremium', 'cubiccapacity']\n",
    "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())\n",
    "\n",
    "# Categorical columns - Impute with mode\n",
    "categorical_cols = ['MaritalStatus', 'Gender', 'Citizenship', 'LegalType']\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Remove rows with excessive missing data (threshold 70%)\n",
    "df = df.dropna(thresh=int(0.7*df.shape[1]), axis=0)\n",
    "\n",
    "# Feature Engineering\n",
    "\n",
    "# 1. Age of Car (CarAge)\n",
    "df['TransactionDate'] = pd.to_datetime(df['TransactionMonth'])  # Convert to datetime\n",
    "df['CarAge'] = df['TransactionDate'].dt.year - df['RegistrationYear']\n",
    "\n",
    "# 2. Insured Value per Year (InsuredPerYear)\n",
    "df['InsuredPerYear'] = df['SumInsured'] / df['CarAge'].replace(0, 1)  # Avoid division by zero\n",
    "\n",
    "# 3. Claims Frequency (ClaimsPerYear)\n",
    "df['ClaimsPerYear'] = df['TotalClaims'] / df['CarAge'].replace(0, 1)\n",
    "\n",
    "# 4. Client Risk Profile based on client info\n",
    "df['ClientRiskScore'] = np.where(df['IsVATRegistered'] == 'Yes', 1, 0)\n",
    "df['ClientRiskScore'] += np.where(df['MaritalStatus'] == 'Single', 1, 0)\n",
    "df['ClientRiskScore'] += np.where(df['Citizenship'] == 'South Africa', 0, 1)  # Higher risk if not South African\n",
    "\n",
    "# 5. Vehicle Risk Score based on car info\n",
    "df['VehicleRiskScore'] = np.where(df['VehicleType'] == 'Passenger Vehicle', 1, 0)\n",
    "df['VehicleRiskScore'] += df['Cylinders'] / df['Cylinders'].max()  # Normalize cylinder count as risk factor\n",
    "\n",
    "# Save the processed data\n",
    "df.to_csv('processed_insurance_data.csv', index=False)\n",
    "\n",
    "print(\"Data preparation and feature engineering complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\biement fanteye\\AppData\\Local\\Temp\\ipykernel_4264\\2596673082.py:5: DtypeWarning: Columns (32,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('processed_insurance_data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical data encoding complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the processed dataset\n",
    "df = pd.read_csv('processed_insurance_data.csv')\n",
    "\n",
    "# One-hot encoding for categorical columns with many categories\n",
    "# This avoids creating too many dummy variables for high-cardinality features.\n",
    "one_hot_cols = ['Province', 'MainCrestaZone', 'SubCrestaZone', 'VehicleType', 'make', 'Model', 'bodytype']\n",
    "\n",
    "df = pd.get_dummies(df, columns=one_hot_cols, drop_first=True)\n",
    "\n",
    "# Label encoding for binary or ordinal categorical columns\n",
    "label_cols = ['Gender', 'MaritalStatus', 'IsVATRegistered', 'AlarmImmobiliser', 'TrackingDevice', 'NewVehicle', 'WrittenOff', 'Rebuilt', 'Converted', 'CrossBorder']\n",
    "\n",
    "# Initialize label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding\n",
    "for col in label_cols:\n",
    "    df[col] = label_encoder.fit_transform(df[col].astype(str))\n",
    "\n",
    "# Save the fully encoded dataset\n",
    "df.to_csv('encoded_insurance_data.csv', index=False)\n",
    "\n",
    "print(\"Categorical data encoding complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UnderwrittenCoverID', 'PolicyID', 'TransactionMonth',\n",
       "       'IsVATRegistered', 'Citizenship', 'LegalType', 'Title', 'Language',\n",
       "       'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province',\n",
       "       'PostalCode', 'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'mmcode',\n",
       "       'VehicleType', 'RegistrationYear', 'make', 'Model', 'Cylinders',\n",
       "       'cubiccapacity', 'kilowatts', 'bodytype', 'NumberOfDoors',\n",
       "       'VehicleIntroDate', 'CustomValueEstimate', 'AlarmImmobiliser',\n",
       "       'TrackingDevice', 'CapitalOutstanding', 'NewVehicle', 'WrittenOff',\n",
       "       'Rebuilt', 'Converted', 'CrossBorder', 'NumberOfVehiclesInFleet',\n",
       "       'SumInsured', 'TermFrequency', 'CalculatedPremiumPerTerm',\n",
       "       'ExcessSelected', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section',\n",
       "       'Product', 'StatutoryClass', 'StatutoryRiskType', 'TotalPremium',\n",
       "       'TotalClaims', 'TransactionDate', 'CarAge', 'InsuredPerYear',\n",
       "       'ClaimsPerYear', 'ClientRiskScore', 'VehicleRiskScore'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\biement fanteye\\AppData\\Local\\Temp\\ipykernel_4264\\3969896274.py:5: DtypeWarning: Columns (8,9,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('encoded_insurance_data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-test split complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the encoded dataset\n",
    "df = pd.read_csv('encoded_insurance_data.csv')\n",
    "\n",
    "# Define your target variable and features\n",
    "X = df.drop(columns=['TotalPremium', 'TotalClaims'])  # Features\n",
    "y = df['TotalPremium']  # Target variable (adjust as necessary)\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the train and test sets to CSV (optional)\n",
    "X_train.to_csv('X_train.csv', index=False)\n",
    "X_test.to_csv('X_test.csv', index=False)\n",
    "y_train.to_csv('y_train.csv', index=False)\n",
    "y_test.to_csv('y_test.csv', index=False)\n",
    "\n",
    "print(\"Train-test split complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\biement fanteye\\AppData\\Local\\Temp\\ipykernel_4264\\201061600.py:9: DtypeWarning: Columns (8,9,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('encoded_insurance_data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns: Index(['Citizenship', 'LegalType', 'Title', 'Language', 'Bank', 'AccountType',\n",
      "       'Country', 'ItemType', 'VehicleIntroDate', 'CapitalOutstanding',\n",
      "       'TermFrequency', 'ExcessSelected', 'CoverCategory', 'CoverType',\n",
      "       'CoverGroup', 'Section', 'Product', 'StatutoryClass',\n",
      "       'StatutoryRiskType'],\n",
      "      dtype='object')\n",
      "UnderwrittenCoverID     int64\n",
      "PolicyID                int64\n",
      "TransactionMonth        int32\n",
      "IsVATRegistered         int64\n",
      "Citizenship            object\n",
      "                        ...  \n",
      "bodytype_S/D             bool\n",
      "bodytype_S/W             bool\n",
      "bodytype_SUV             bool\n",
      "TransactionYear         int32\n",
      "TransactionDay          int32\n",
      "Length: 592, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('encoded_insurance_data.csv')\n",
    "\n",
    "# Convert date columns to datetime format (assuming 'TransactionDate' is the date column)\n",
    "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'])\n",
    "\n",
    "# Extract relevant features from the date\n",
    "df['TransactionYear'] = df['TransactionDate'].dt.year\n",
    "df['TransactionMonth'] = df['TransactionDate'].dt.month\n",
    "df['TransactionDay'] = df['TransactionDate'].dt.day\n",
    "\n",
    "# Drop the original date column if it's no longer needed\n",
    "df.drop(columns=['TransactionDate'], inplace=True)\n",
    "\n",
    "# Define your target variable and features\n",
    "X = df.drop(columns=['TotalPremium', 'TotalClaims'])  # Features\n",
    "y = df['TotalPremium']  # Target variable\n",
    "\n",
    "# Step 1: Check for non-numeric columns\n",
    "non_numeric_columns = X.select_dtypes(include=['object']).columns\n",
    "print(\"Non-numeric columns:\", non_numeric_columns)\n",
    "\n",
    "# Step 2: Replace empty strings or spaces with NaN\n",
    "X.replace(r'^\\s*$', pd.NA, regex=True, inplace=True)\n",
    "\n",
    "# Step 3: Handle missing values (you can drop or fill them)\n",
    "X.fillna(0, inplace=True)  # Filling missing values with 0 (you can use mean/median if preferred)\n",
    "\n",
    "# Step 4: Ensure all features are numeric\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\biement fanteye\\AppData\\Local\\Temp\\ipykernel_4264\\1517319579.py:9: DtypeWarning: Columns (8,9,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('encoded_insurance_data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: Index(['Citizenship', 'LegalType', 'Title', 'Language', 'Bank', 'AccountType',\n",
      "       'Country', 'ItemType', 'VehicleIntroDate', 'CapitalOutstanding',\n",
      "       'TermFrequency', 'ExcessSelected', 'CoverCategory', 'CoverType',\n",
      "       'CoverGroup', 'Section', 'Product', 'StatutoryClass',\n",
      "       'StatutoryRiskType'],\n",
      "      dtype='object')\n",
      "Linear Regression - MSE: 14878.05, R2: 0.46\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('encoded_insurance_data.csv')\n",
    "\n",
    "# Convert date columns to datetime format (assuming 'TransactionDate' is the date column)\n",
    "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'])\n",
    "\n",
    "# Extract relevant features from the date\n",
    "df['TransactionYear'] = df['TransactionDate'].dt.year\n",
    "df['TransactionMonth'] = df['TransactionDate'].dt.month\n",
    "df['TransactionDay'] = df['TransactionDate'].dt.day\n",
    "\n",
    "# Drop the original date column if it's no longer needed\n",
    "df.drop(columns=['TransactionDate'], inplace=True)\n",
    "\n",
    "# Step 1: Identify categorical columns\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "print(\"Categorical columns:\", categorical_columns)\n",
    "\n",
    "# Step 2: Convert categorical columns to numeric using one-hot encoding\n",
    "df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Define your target variable and features\n",
    "X = df.drop(columns=['TotalPremium', 'TotalClaims'])  # Features\n",
    "y = df['TotalPremium']  # Target variable\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 1. Linear Regression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_pred_lin = lin_reg.predict(X_test)\n",
    "\n",
    "# Evaluate Linear Regression\n",
    "lin_mse = mean_squared_error(y_test, y_pred_lin)\n",
    "lin_r2 = r2_score(y_test, y_pred_lin)\n",
    "print(f'Linear Regression - MSE: {lin_mse:.2f}, R2: {lin_r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - MSE: 1942.04, R2: 0.93\n"
     ]
    }
   ],
   "source": [
    "# 2. Random Forest Regressor\n",
    "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "y_pred_rf = rf_reg.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "rf_mse = mean_squared_error(y_test, y_pred_rf)\n",
    "rf_r2 = r2_score(y_test, y_pred_rf)\n",
    "print(f'Random Forest - MSE: {rf_mse:.2f}, R2: {rf_r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - MSE: 7939.03, R2: 0.71\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert pandas DataFrames to numpy arrays\n",
    "X_train_np = X_train.to_numpy()\n",
    "X_test_np = X_test.to_numpy()\n",
    "\n",
    "# Fit the XGBoost model\n",
    "xgb_reg = XGBRegressor(n_estimators=100, random_state=42)\n",
    "xgb_reg.fit(X_train_np, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_reg.predict(X_test_np)\n",
    "\n",
    "# Evaluate XGBoost\n",
    "xgb_mse = mean_squared_error(y_test, y_pred_xgb)\n",
    "xgb_r2 = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f'XGBoost - MSE: {xgb_mse:.2f}, R2: {xgb_r2:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
